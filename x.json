{
  "name": "webrtc",
  "description": "WebRTC for ChiÏ‡",
  "version": "0.0.2",
  "repository": {
    "type": "git",
    "url": "https://github.com/nodule/webrtc.git"
  },
  "dependencies": {
    "webrtc": "1.x.x",
    "hark": "0.x.x",
    "getusermedia": "0.x.x",
    "attachmediastream": "0.x.x"
  },
  "nodes": [
    {
      "ports": {
        "input": {
          "element": {
            "title": "Media Element",
            "type": "HTMLElement"
          },
          "stream": {
            "title": "Stream",
            "type": "DOMString"
          }
        },
        "output": {
          "element": {
            "title": "Media Element",
            "type": "HTMLElement"
          },
          "stream": {
            "title": "Stream",
            "type": "DOMString"
          }
        }
      },
      "require": {
        "attachmediastream": "0.x.x"
      },
      "phrases": {
        "active": "Attaching Media Stream"
      },
      "description": "AttachMediaStream (microphone, camera)",
      "ns": "webrtc",
      "name": "attachMediaStream",
      "fn": "attachmediastream(input.element, input.stream)\noutput = input\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "function",
            "required": true
          },
          "id": {
            "title": "ID",
            "type": "string"
          },
          "type": {
            "title": "Type",
            "type": "string",
            "enum": [
              "video",
              "audio",
              "screen"
            ],
            "default": "video"
          },
          "oneway": {
            "title": "One Way?",
            "type": "boolean",
            "default": false
          },
          "sharemyscreen": {
            "title": "Share My Screen",
            "type": "boolean",
            "default": false
          },
          "stream": {
            "title": "WebRTC Stream",
            "type": "function"
          }
        },
        "output": {
          "peer": {
            "title": "Peer",
            "type": "function"
          }
        }
      },
      "phrases": {
        "active": "Creating Peer"
      },
      "description": "Create Peer",
      "ns": "webrtc",
      "name": "createPeer",
      "fn": "webrtc = input.webrtc;\ndelete input.webrtc;\noutput = {\n  peer: webrtc.createPeer(input)\n};\n"
    },
    {
      "ports": {
        "input": {},
        "output": {
          "error": {
            "title": "Error",
            "type": "object"
          },
          "stream": {
            "title": "Stream",
            "type": "DOMString"
          }
        }
      },
      "require": {
        "getusermedia": "0.x.x"
      },
      "phrases": {
        "active": "Getting User Media"
      },
      "description": "Get User Media (microphone, camera)",
      "ns": "webrtc",
      "name": "getUserMedia",
      "fn": "var speachEvents = hark(input.stream);\n\noutput = function (cb) {\n\n  cb({\n    stream: input.stream\n  });\n\n  speechEvents.on('speaking', function () {\n    cb({\n      speaking: true\n    });\n  });\n\n  speechEvents.on('volume_change', function (volume, threshold) {\n    cb({\n      volume: volume,\n      treshold: treshold\n    });\n  });\n\n  speechEvents.on('stopped_speaking', function () {\n    cb({\n      speaking: false\n    });\n  });\n\n};\n"
    },
    {
      "ports": {
        "input": {
          "stream": {
            "title": "Stream",
            "type": "DOMString",
            "description": "e.g. document.querySelector('audio')",
            "required": true
          }
        },
        "output": {
          "stream": {
            "title": "Stream",
            "type": "DOMString"
          },
          "speaking": {
            "title": "Speaking",
            "type": "boolean"
          },
          "volume": {
            "title": "volume",
            "type": "number"
          },
          "threshold": {
            "title": "Treshold",
            "type": "number"
          }
        }
      },
      "require": {
        "hark": "0.x.x"
      },
      "phrases": {
        "active": "Harking"
      },
      "description": "Hark",
      "ns": "webrtc",
      "name": "hark",
      "fn": "var speachEvents = hark(input.stream);\n\noutput = function (cb) {\n\n  cb({\n    stream: input.stream\n  });\n\n  speechEvents.on('speaking', function () {\n    cb({\n      speaking: true\n    });\n  });\n\n  speechEvents.on('volume_change', function (volume, threshold) {\n    cb({\n      volume: volume,\n      treshold: treshold\n    });\n  });\n\n  speechEvents.on('stopped_speaking', function () {\n    cb({\n      speaking: false\n    });\n  });\n\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Muting media"
      },
      "description": "Mute",
      "ns": "webrtc",
      "name": "mute",
      "fn": "input.webrtc.mute();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Pausing"
      },
      "description": "Pause",
      "ns": "webrtc",
      "name": "pause",
      "fn": "input.webrtc.pause();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Pausing video"
      },
      "description": "Pause Video",
      "ns": "webrtc",
      "name": "pauseVideo",
      "fn": "input.webrtc.pauseVideo();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Resuming"
      },
      "description": "Resume",
      "ns": "webrtc",
      "name": "resume",
      "fn": "input.webrtc.resume();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Resuming video"
      },
      "description": "Resume Video",
      "ns": "webrtc",
      "name": "resumeVideo",
      "fn": "input.webrtc.resumeVideo();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          },
          "media": {
            "type": "object",
            "properties": {
              "audio": {
                "title": "Audio?",
                "type": "boolean",
                "default": true
              },
              "video": {
                "title": "Video?",
                "type": "boolean",
                "default": true
              }
            }
          }
        },
        "output": {
          "error": {
            "title": "Error",
            "type": "object"
          },
          "stream": {
            "title": "Stream",
            "type": "DOMString"
          }
        }
      },
      "phrases": {
        "active": "Starting local media"
      },
      "description": "Start Local Media",
      "ns": "webrtc",
      "name": "startLocalMedia",
      "fn": "output = [input.webrtc, 'startLocalMedia', input.media];\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Stopping local media"
      },
      "description": "Stop Local Media",
      "ns": "webrtc",
      "name": "stopLocalMedia",
      "fn": "input.webrtc.stopLocalMedia();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC",
            "required": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          }
        }
      },
      "phrases": {
        "active": "Unmuting media"
      },
      "description": "Unmute",
      "ns": "webrtc",
      "name": "unmute",
      "fn": "input.webrtc.unmute();\noutput = {\n  webrtc: input.webrtc\n};\n"
    },
    {
      "ports": {
        "input": {
          "debug": {
            "title": "Debug",
            "type": "boolean",
            "default": false
          },
          "localVideoEl": {
            "title": "Local Video Element",
            "type": "any",
            "required": true
          },
          "remoteVideosEl": {
            "title": "Remote Videos Element",
            "type": "any",
            "required": true
          },
          "autoRequestMedia": {
            "title": "Auto Request Media",
            "type": "boolean",
            "default": false
          },
          "autoAdjustMic": {
            "title": "Auto Adjust Microphone",
            "type": "boolean",
            "default": false
          },
          "media": {
            "type": "object",
            "properties": {
              "audio": {
                "title": "Audio?",
                "type": "boolean",
                "default": true
              },
              "video": {
                "title": "Video?",
                "type": "boolean",
                "default": true
              }
            }
          },
          "detectSpeakingEvents": {
            "title": "Detect Speaking Events",
            "type": "boolean",
            "default": true
          },
          "enableDataChannels": {
            "title": "Enable Data Channels",
            "type": "boolean",
            "default": true
          }
        },
        "output": {
          "webrtc": {
            "title": "WebRTC",
            "type": "WebRTC"
          },
          "localStream": {
            "title": "Local Stream",
            "type": "DOMString"
          },
          "localStreamStopped": {
            "title": "Local Stream Stopped",
            "type": "boolean"
          },
          "audio": {
            "title": "Audio ON/OFF",
            "type": "boolean"
          },
          "video": {
            "title": "Video ON/OFF",
            "type": "boolean"
          },
          "speaking": {
            "title": "Speaking YES/NO",
            "type": "boolean"
          },
          "message": {
            "title": "Message",
            "type": "any"
          },
          "peerStreamAdded": {
            "title": "Peer Stream Added",
            "type": "DOMString"
          },
          "peerStreamRemoved": {
            "title": "Peer Stream Removed",
            "type": "DOMString"
          }
        }
      },
      "require": {
        "webrtc": "1.x.x"
      },
      "phrases": {
        "active": "Launching WebRTC!"
      },
      "description": "WebRTC",
      "ns": "webrtc",
      "name": "webrtc",
      "fn": "output = function (cb) {\n\n  var wrtc = new webrtc(input);\n\n  // our direct port.\n  cb({\n    webrtc: wrtc\n  });\n\n  // send local stream\n  wrtc.on('localStream', function (stream) {\n    cb({\n      localStream: stream\n    });\n  });\n\n  wrtc.on('localStreamStopped', function () {\n    cb({\n      localStreamStopped: true\n    });\n  });\n\n  wrtc.on('audioOn', function () {\n    cb({\n      audio: true\n    });\n  });\n\n  wrtc.on('audioOff', function () {\n    cb({\n      audio: false\n    });\n  });\n\n  wrtc.on('videoOn', function () {\n    cb({\n      video: true\n    });\n  });\n\n  wrtc.on('videoOff', function () {\n    cb({\n      video: false\n    });\n  });\n\n  wrtc.on('speaking', function () {\n    cb({\n      speaking: true\n    });\n  });\n\n  wrtc.on('stoppedSpeaking', function () {\n    cb({\n      speaking: false\n    });\n  });\n\n  wrtc.on('message', function (message) {\n    cb({\n      message: message\n    });\n  });\n\n  wrtc.on('peerStreamAdded', function (peer) {\n    cb({\n      peerStreamAdded: peer\n    });\n  });\n\n  wrtc.on('peerStreamRemoved', function (peer) {\n    cb({\n      peerStreamRemoved: peer\n    });\n  });\n\n};\n"
    }
  ],
  "twigs": []
}